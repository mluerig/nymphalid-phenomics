{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c71e668",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "Converted from `01_feature_extraction.py`.\n",
    "\n",
    "This notebook runs the feature extraction pipeline: loading mask files, computing embeddings, extracting image features, and computing CLIP-based text similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e2c228",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "from autodistill_grounded_sam import GroundedSAM\n",
    "from autodistill.detection import CaptionOntology\n",
    "import torch\n",
    "\n",
    "# local utils\n",
    "from utils import utils_python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5653b84",
   "metadata": {},
   "source": [
    "## Prepare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set working directory\n",
    "os.chdir(r\"D:/git-repos/mluerig/nymphalid-phenomics/\")\n",
    "\n",
    "# optional: suppress warnings (there will be a lot of them)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## check for cuda \n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eb8a8b",
   "metadata": {},
   "source": [
    "## Get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = f\"data_raw/images_sample\"\n",
    "\n",
    "file_dict = {}\n",
    "for file_name in os.listdir(input_dir):\n",
    "    filepath = os.path.join(input_dir, file_name)\n",
    "    file_dict[file_name] = {\n",
    "        \"image_name\" : file_name,\n",
    "        \"image_path\" : filepath\n",
    "        }\n",
    "\n",
    "data_imgs = pd.DataFrame.from_dict(file_dict, orient=\"index\")\n",
    "data_imgs.reset_index(inplace=True, drop=True)\n",
    "\n",
    "data_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3da94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## file I/O\n",
    "path_data_results = \"data_raw/tables/segmentation_results.pkl\"\n",
    "output_dir = \"data_raw/segmentation_masks/all_masks\"\n",
    "\n",
    "## set of processed images\n",
    "dict_results = {}\n",
    "\n",
    "#%% model setup\n",
    "model = GroundedSAM(\n",
    "    ontology=CaptionOntology({\"butterfly\": \"butterfly\",}),\n",
    "    text_threshold = 0.1,\n",
    "    box_threshold = 0.1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_area = 10_000 ## this may need to be adjusted based on image resolution, but you do probably want to filter out small masks\n",
    "\n",
    "pbar = tqdm(total=len(data_imgs), position=0, leave=False, desc=\"Segmenting images\")\n",
    "for idx1, row in data_imgs.iterrows():\n",
    "\n",
    "    image_name = row[\"image_name\"]\n",
    "    base_image_name = os.path.splitext(image_name)[0]\n",
    "    \n",
    "    # Load image and predict\n",
    "    try:\n",
    "        image = cv2.imread(row[\"image_path\"])\n",
    "        assert image is not None, \"Failed to load the image.\"\n",
    "    except:\n",
    "        dict_results[base_image_name] = {\"status\": \"no detections\", \"image_name\": image_name}\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "    \n",
    "    ## do prediction\n",
    "    result = model.predict(image)\n",
    "    \n",
    "    # Check for masks and process\n",
    "    if len(result.mask) > 0:\n",
    "        for idx2, (area, mask) in enumerate(zip(result.area, result.mask)):\n",
    "            detection_name = base_image_name + f\"_{idx2+1}.png\"\n",
    "                \n",
    "            # Filter mask and save. if mask is below min_area, it will return an empty dict\n",
    "            roi, info = utils_python.filter_mask(image, mask, min_area)\n",
    "            if roi is not None:\n",
    "                cv2.imwrite(os.path.join(output_dir, detection_name), roi)\n",
    "                                \n",
    "            # Store info\n",
    "            info[\"confidence\"] = result.confidence[idx2]\n",
    "            info[\"area\"] = area\n",
    "            info[\"mask_idx\"] = idx2 + 1\n",
    "            info[\"image_name\"] = image_name\n",
    "            dict_results[detection_name] = info\n",
    "    else:\n",
    "        # Add an empty entry if no detections\n",
    "        dict_results[detection_name] = {\"status\": \"no detections\", \"image_name\": image_name}\n",
    "\n",
    "    pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e74730",
   "metadata": {},
   "source": [
    "## post-processing\n",
    "\n",
    "what follows here is an extensive post-processing pipeline that is explained in the methods part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f48c0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nymphalidae1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
